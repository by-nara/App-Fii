{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZaDj4B1rQVSrAHEQSatqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/by-nara/App-Fii/blob/main/rede_neural_do_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1I-UgB7fNLoP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision # Adicionando a importação aqui para garantir\n",
        "\n",
        "transform = transforms.ToTensor() #definindo a conversão de imagem para tensor\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) #Carrega a parte de treino do dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) #Cria um buffer para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) #Carrega a parte de validação do dataset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes"
      ],
      "metadata": {
        "id": "tl2TylXeOZIU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = dataiter.__next__()\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "ILhVIQTPPRQY",
        "outputId": "ee74ed9a-56b4-4cdb-ae79-f425c2dc3629"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) #para verificar as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) #para verificar as dimensões do tensor de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGpdwxS5Pjxn",
        "outputId": "b4acba0e-f6e3-420a-e32c-1671f1407cf0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neuronios que se ligam a 128\n",
        "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neuronios que se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neuronios que se ligam a 10\n",
        "        # para a camada de saída não e necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self, X):\n",
        "            X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
        "            X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
        "            X = self.linear3(X) # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "            return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "6xHlIgYJP_co"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) #define a politica de atualização dos pesos e da blas\n",
        "    inicio = time() # timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "    criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
        "    EPOCHS = 100 # numero de epochs que o algoritmo rodará\n",
        "    modelo.train() # ativando o modo de treinamento do modelo\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        perda_acumulada = 0 # inicialização da perda acumulada do epoch em questão\n",
        "\n",
        "        for imagens, etiquetas in trainloader:\n",
        "\n",
        "            imagens = imagens.view(imagens.shape[0], -1) # transformando a imagem em um vetor\n",
        "            otimizador.zero_grad() # zerando os gradientes\n",
        "\n",
        "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
        "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda\n",
        "\n",
        "            perda_instantanea.backward() # backpropagation\n",
        "\n",
        "            otimizador.step() # atualizando os pesos\n",
        "\n",
        "            perda_acumulada += perda_instantanea.item() # atualizando a perda acumulada\n",
        "\n",
        "        else:\n",
        "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "    print(\"\\nTempo de treino(em minutos) =\", (time()-inicio)/60)"
      ],
      "metadata": {
        "id": "oMGt_qKBR7ke"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas = 0, 0\n",
        "    for imagens, etiquetas in valloader:\n",
        "        for i in range(len(etiquetas)):\n",
        "            img = imagens[i].view(1, 784)\n",
        "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
        "            with torch.no_grad():\n",
        "              logps = modelo(img.to(device)) # output do modelo em escala logaritmica\n",
        "\n",
        "            ps = torch.exp(logps) # converte output para escala normal(lembrando que é um tensor)\n",
        "            probab = list(ps.cpu().numpy()[0])\n",
        "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo previu\n",
        "            if(etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n",
        "              conta_corretas += 1\n",
        "            conta_todas += 1\n",
        "\n",
        "    print(\"Total de imagens testadas =\", conta_todas)\n",
        "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "_PiLhU5KSxLJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EB2F7_qTdsB",
        "outputId": "25894218-9f11-415b-8700-3aae0d56d601"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}